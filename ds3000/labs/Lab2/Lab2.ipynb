{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52a63c5-8632-42cf-a598-1f9b9fcf118e",
   "metadata": {},
   "source": [
    "# Lab 2 (Due @ by 1:59 am via Canvas/Gradescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4381c6-9601-4e78-806e-2c06d0aaea20",
   "metadata": {},
   "source": [
    "Your Name: Tejadatta Kalapatapu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f3831-9eab-4c04-a0e5-dbe043d32320",
   "metadata": {},
   "source": [
    "Due: Saturday, Oct. 5 @ 1:59 am\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the `ipynb` file to gradescope. **In addition:**\n",
    "- Make sure your name is entered above\n",
    "- Make sure you comment your code effectively\n",
    "- If problems are difficult for the TAs/Profs to grade, you will lose points\n",
    "\n",
    "### Tips for success\n",
    "- Collaborate: bounce ideas off of each other, if you are having trouble you can ask your classmates or Dr. Singhal for help with specific issues, however...\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](http://www.northeastern.edu/osccr/academic-integrity), i.e. you are welcome to **talk about** (*not* show each other your answers to) the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128c2500-de83-4732-a3ac-78ccdd6094f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might use the below modules on this lab\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197c58c-8285-446e-bb07-347de63ce276",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Cleaning\n",
    "### Part 1.1: Grabbing Data and Preliminary Cleaning (10 points)\n",
    "\n",
    "We wish to create a data frame that includes all the spells for each class (a \"class\" is something like a \"wizard\", or a \"bard\") in Dungeons and Dragons 5th Edition, which you can find [here](http://dnd5e.wikidot.com/). Your final data frame should look something like:\n",
    "\n",
    "| Class     | Level     | Spell Name    | School      | Casting Time | Range                | Duration      | Components |\n",
    "|----------:|----------:|--------------:|------------:|-------------:|---------------------:|--------------:|-----------:|\n",
    "| Artificer | Level 0   | Acid Splash   | Conjuration | 1 Action     | 60 Feet              | Instantaneous | V, S       |\n",
    "| Artificer | Level 0   | Booming Blade | Evocation   | 1 Action     | Self (5-foot radius) | 1 Round       | S, M       |\n",
    "| ...       | ...       | ...           | ...         | ...          | ...                  | ...           | ...        |\n",
    "| Wizard    | Level 9   | Wish          | Conjuration | 1 Action     | Self                 | Instantaneous | V          |\n",
    "\n",
    "Below are two functions which:\n",
    "- takes a class (string) as an argument and returns the tables from the class's DND wiki spell page in a dictionary for each spell level\n",
    "- takes a list of classes, applies the first function to each of them, then combines all the tables into a data frame, including a column with class name and a column with spell level\n",
    "\n",
    "**DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTIONS.**\n",
    "\n",
    "**In a markdown cell** create a bullet point list where you explain each what each chunk of code does. Your bullet point list should have **FIVE** bullet points/explanations corresponding to the four chunks below the `# EXPLAIN THIS (number)` comments. You must accurately summarize the content and procedure of each code chunk. **Talking to your neighbors/group about this is highly recommended.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8320bfe-d77c-4b10-a59c-c7b4c046d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_spell_dict(dnd_class):\n",
    "    \"\"\" takes a D&D class (string) and gets the spell tables and saves them in a dictionary\n",
    "    \n",
    "    Args:\n",
    "        dnd_class (str): the D&D class\n",
    "        \n",
    "    Returns:\n",
    "        table_dict (dict): a dictionary of tables, one for each spell level\n",
    "    \"\"\"\n",
    "\n",
    "    # EXPLAIN THIS (1)\n",
    "    url = f'http://dnd5e.wikidot.com/spells:{dnd_class}'\n",
    "    tables = pd.read_html(url)\n",
    "    table_dict = {}\n",
    "    for i in range(len(tables)):\n",
    "        table_dict[f'Level {i}'] = tables[i]\n",
    "\n",
    "    return table_dict\n",
    "\n",
    "def get_full_spell_df(class_list):\n",
    "    \"\"\" takes a list of D&D classes (list of strings), applies the get_class_spell_dict() function to them, and then combines them into a data frame\n",
    "\n",
    "    Args:\n",
    "        class_list (list): a list of strings\n",
    "\n",
    "    Returns:\n",
    "        spells_df (data frame): a data frame with all the spells\n",
    "    \"\"\"\n",
    "\n",
    "    spells_df = pd.DataFrame()\n",
    "    level_list = []\n",
    "    long_class_list = []\n",
    "    \n",
    "    # EXPLAIN THIS (2)\n",
    "    for class_ in class_list:\n",
    "        class_dict = get_class_spell_dict(class_)\n",
    "        class_df = pd.DataFrame()\n",
    "\n",
    "        # EXPLAIN THIS (3)\n",
    "        for level in class_dict:\n",
    "            level_list.append([level] * len(class_dict[level]))\n",
    "            class_df = pd.concat([class_df, class_dict[level]])\n",
    "\n",
    "        # EXPLAIN THIS (4)\n",
    "        long_class_list.append([class_] * len(class_df))\n",
    "        spells_df = pd.concat([spells_df, class_df])\n",
    "\n",
    "    # EXPLAIN THIS (5)\n",
    "    spells_df.insert(0, 'Level', [item for sublist in level_list for item in sublist])\n",
    "    spells_df.insert(0, 'Class', [item for sublist in long_class_list for item in sublist])\n",
    "    \n",
    "    return spells_df\n",
    "\n",
    "class_list = ['Artificer', 'Bard', 'Cleric', 'Druid', 'Paladin', 'Ranger', 'Sorcerer', 'Warlock', 'Wizard']\n",
    "notclean_df = get_full_spell_df(class_list)\n",
    "notclean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252276e-c8c3-4745-8ad0-736fcfe202d7",
   "metadata": {},
   "source": [
    "Your answers here:\n",
    "\n",
    "- The url link is used to scrape the spell list for a specific dnd class and the next line is used to read the HTML tables from the url and return the dataframes on the page, each one being spells for a certain level. Then an empty dictionary is created and the for loop just adds each table of spells to the dictionary \n",
    "- The for loop goes through every class in the \"class_list\" and for each class, the function \"get_class_spell_dict\" is called on and the spell tables are obtained from each spell level and they are stored in the empty dataframe \"class_df\" \n",
    "- The for loop is going through each level in \"class_dict\" and appends the level data to \"level_list\" and then concatenates the spell level to \"class_df\"\n",
    "- The class names are appended to \"long_class_list\" and concatenates \"class_df\" to \"spells_df\"\n",
    "- Two new columns, \"Level\" and \"Class\", are inserted into \"spells_df\" by using \"level_list\" and \"long_class_list\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780411ad-21a0-4b49-8a88-ebb19c083bb2",
   "metadata": {},
   "source": [
    "### Part 1.2: More Cleaning (15 points)\n",
    "\n",
    "The \"final\" data frame from the previous part is still not as clean as it could be. In a markdown cell, perform these two tasks:\n",
    "\n",
    "1. Write a short paragraph (at least four sentences) discussing what else you would do to continue cleaning up the data\n",
    "2. Think about the `Components` column specifically, write out some pseudo code (you can see how I did the below example by double clicking on this cell) that roughly outlines how you would go about cleaning that column\n",
    "\n",
    "```\n",
    "def my_cleaning_func(column):\n",
    "    \"\"\" this function cleans a column from a data frame\n",
    "\n",
    "    Args: column (Series)\n",
    "\n",
    "    Returns: clean_column (Series)\n",
    "    \"\"\"\n",
    "\n",
    "    # take the column\n",
    "    # clean the column (I have written comments for these steps, YOU SHOULD WRITE PSEUDO-CODE)\n",
    "    # save it as clean_column\n",
    "\n",
    "    return clean_column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e755d-c469-432a-9303-f8d0e1b6e691",
   "metadata": {},
   "source": [
    "Your answers here:\n",
    "\n",
    "- To continue cleaning up the data, I would remove all duplicate values first. Then I would convert all the data to its proper data type. I would also create separate columns for the components for further clarity and ease of access. Finally, I would create consistent values for the \"duration\" and \"range\" columns because they are all different strings that are hard to manipulate as of right now because of the specific types of wording.\n",
    "-\n",
    "\n",
    "```\n",
    "def clean_components(column):\n",
    "    \"\"\" This function cleans the Components column from the spells dataframe \n",
    "    \n",
    "    Arg: column (Series)\n",
    "    \n",
    "    Returns: clean_column (Series)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #empty lists for each component\n",
    "    v = []\n",
    "    s = []\n",
    "    m = []\n",
    "\n",
    "    #going through all the entries\n",
    "    for entry in column:\n",
    "        #splitting the components\n",
    "        c = entry.upper().split(', ')\n",
    "        \n",
    "        #check if the component exists in that spell and append if it does\n",
    "        v.append('Verbal' in c)\n",
    "        s.append('Somatic' in c)\n",
    "        m.append('Material' in c)\n",
    "    \n",
    "    #new cleaned df\n",
    "    clean_column = pd.DataFrame({\n",
    "        'Verbal': verbal,\n",
    "        'Somatic': somatic,\n",
    "        'Material': material\n",
    "    })\n",
    "\n",
    "    return clean_column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aac814-940d-4a04-9614-48af99c4b92a",
   "metadata": {},
   "source": [
    "# Part 2: Summarizing and Visualizing Data\n",
    "\n",
    "This problem uses `evdataset.csv`, available in the Labs Module on Canvas, which was taken and adapted from Kaggle (no longer hosted) and contains a sample of 194 electric vehicles on the market until 2022. The full dataset includes basic technical specifications, battery capacity and range in various weather and road conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c519188-f4b7-425f-a2b9-3766d28a3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ev = pd.read_csv('evdataset.csv', index_col='id')\n",
    "df_ev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88693d-62b2-4833-b9e7-3e71b72b9a39",
   "metadata": {},
   "source": [
    "## Part 2.1: Numeric Summaries (25 points)\n",
    "\n",
    "On your own or with a classmate, discuss which features you think would be most interesting to compare across different drives. Pick two or three of them and, after using `.groupby()` to group by the `drive` feature, calculate for all of them:\n",
    "\n",
    "- means\n",
    "- medians\n",
    "- standard deviations\n",
    "\n",
    "Then, using the original data set, look at the pairwise correlations (with the correlation matrix, check out the [`pd.corr()` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)). Finally, **in a markdown cell** discuss your key takeaways from the numeric summaries you calculated, and what the correlations were between your chosen features. Where they among the strongest/weakest relationships? Do you think the type of drive may impact these relationships? Any other interesting results of note?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faa42d-ed97-4fc3-a912-82369fc29567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a group of \"electricrange\", \"totalpower\", and \"batterycapacity\"\n",
    "group = df_ev.groupby(\"drive\")[[\"electricrange\", \"totalpower\", \"batterycapacity\"]]\n",
    "\n",
    "#getting the mean, median, and standard deviation\n",
    "means = group.mean()\n",
    "med = group.median()\n",
    "stddev = group.std()\n",
    "\n",
    "print(\"Means:\\n\", means)\n",
    "print(\"\\nMedians:\\n\", med)\n",
    "print(\"\\nStandard Deviations:\\n\", stddev)\n",
    "\n",
    "#getting the correlation matrix\n",
    "corr_mat = df_ev[[\"electricrange\", \"totalpower\", \"batterycapacity\"]].corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", corr_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8945a",
   "metadata": {},
   "source": [
    "Some key takeaways I got from this data is that there is a strong positive correlation between electric range and battery capacity, which make sense because the range would be higher if the battery is better. On the other hand, there is a weak correlation between electric range and total power, meaning a higher power does not lead to a higher range. Furthermore, AWD cars have a pattern of having a higher total power but a lower electric range compared to rear wheel drive cars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebfefb-634b-4806-a1c9-eb1bb1f25f32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad16632-cfb3-4241-a828-a321e75be83e",
   "metadata": {},
   "source": [
    "## Part 2.2: Visual Summaries (25 points)\n",
    "\n",
    "Again choose two or three features (they can be the same or different as those from the previous part) and make a few plots to further your understanding of the data. For the first two plots, you may use any of `matplotlib`, `seaborn` or `plotly` (you may find some easier to use than others). Please make:\n",
    "\n",
    "- Histograms for each drive type (i.e. three histograms, one for each of: AWD, Front, Rear) for one of your chosen features. You may make them separately or within a subplot.\n",
    "- A scatterplot of two of your features, with points colored by drive type.\n",
    "- Check out the [seaborn plot options again](https://seaborn.pydata.org/examples/index.html) and pick one to use with your chosen features (exercise some thought as to what you are hoping the plot will communicate; you may find it worthwhile to discuss options with your classmates).\n",
    "\n",
    "Then, **in a markdown cell** discuss what you learned from the plots you created. If you used the same features that you investigated numerically, did the plots corroborate your findings? Or did they provide new insight? If you used new features, what do the plots tell you about what the numeric reationship(s) between the features might be? Ay other interesting results to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c25c40-efef-4526-a16e-7c1a1d1c04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#creating the histograms using for loop for all types of drive\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, drive in enumerate([\"AWD\", \"Front\", \"Rear\"]):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    df_ev[df_ev[\"drive\"] == drive][\"electricrange\"].hist()\n",
    "    plt.title(f\"{drive} Electric Range\")\n",
    "plt.show()\n",
    "\n",
    "#creating the scatterplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(data = df_ev, x = \"batterycapacity\", y = \"electricrange\", hue = \"drive\")\n",
    "plt.title(\"Battery Capacity vs. Electric Range\")\n",
    "plt.show()\n",
    "\n",
    "#creating the sns plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data = df_ev, x = \"drive\", y = \"totalpower\")\n",
    "plt.title(\"Total Power by Drive Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc093c",
   "metadata": {},
   "source": [
    "The histograms display that the rear wheel drive cars have a broader range of electric range, while vice versa for the front wheel drive. The scatterplot shows what I had said before about the strong positive correlation between electric range and battery capacity and AWD has bigger battery capacities on average. The boxplots show that AWD have the highest total power on average, while the front wheel drive cars have the lowest total power on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c98f8-c0e6-457f-afff-82e92d95a62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "249eca7c-dc1c-4f93-89d2-021290979370",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532b6eb5-bf20-4a91-9967-f78fe2f8c80f",
   "metadata": {},
   "source": [
    "## Part 2.3: Future Considerations (25 points)\n",
    "\n",
    "1) Explicitly calculate the variance of all the numeric features in the raw `df_ev` data set, as well as the covariance matrix. \n",
    "\n",
    "Then, in a few sentences (**in a markdown cell**) discuss in detail:\n",
    "\n",
    "(a) why some variances are larger than others, \n",
    "\n",
    "(b) why the covariances between the different features are not as useful as the correlations you calculated in Part 2.1 (**pick a couple** of example relationships to illustrate the point(s) you make, \n",
    "\n",
    "and (c) if the relationships we see between the features based on the correlation matrix from Part 2.1 are necessarily the true relationships between those features. Think about the meme that was shown in the class:\n",
    "\n",
    "![d](https://miro.medium.com/v2/resize:fit:547/1*2BnD3YAUBGNutkKiG5dKfg.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f4349-a8f6-4e4e-9d5a-625bc54f12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using numbers only\n",
    "numeric_columns = df_ev.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "#variances\n",
    "variances = df_ev[numeric_columns].var()\n",
    "print(\"Variances:\\n\", variances)\n",
    "\n",
    "#covariance matrix\n",
    "cov_matrix = df_ev[numeric_columns].cov()\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db933c4f",
   "metadata": {},
   "source": [
    "a. Some variances are larger than others because of the different units of measurement for throughout the categories, such as length being in millimeters and acceleration being in seconds. Furthermore, electric capacity and total power will also vary heavily because they range from big batteries/motors to small batteries/motors.\n",
    "\n",
    "b. Covariances are not as useful as the correlations I calculated before because they aren't standardized and the way the categories are measured differ, meaning even though the covariance between two variables such as battery capacity and electric range is going to have a positive correlation, its magnitude would be hard to analyze as the  units of measurement are different.\n",
    "\n",
    "c. The relationships we see between the features based on the correlation matrix from Part 2.1 aren't always necessarily true because of the simple fact that correlation does not always imply causation. Two completely different and random variables might have a positive correlation, but they might not have anything to do with each other, such as the meme in the picture, which is comparing their sales to shaved heads, which are completely unrelated but still have a strong positive correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39baab-2750-43a8-a012-4e8899f97ad5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
